name: CI Advanced - Retrain + Artifact + Docker

on:
  push:
    branches: ["main"]
    paths:
      - "MLProject/**"
      - ".github/workflows/ci_advanced.yml"
  workflow_dispatch:

jobs:
  advanced:
    runs-on: ubuntu-latest

    env:
      EXPERIMENT_NAME: HeartDisease_CI
      RUN_NAME: ci-retrain
      DATA_DIR: heart_preprocessed

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "mlflow==2.16.2" pandas scikit-learn numpy

      - name: Set MLflow tracking to local folder
        run: |
          echo "MLFLOW_TRACKING_URI=file:${GITHUB_WORKSPACE}/mlruns" >> $GITHUB_ENV
          echo "MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING=false" >> $GITHUB_ENV

      - name: Debug - verify files
        run: |
          ls -la
          ls -la MLProject
          echo "---- MLproject content ----"
          cat MLProject/MLproject
          echo "---- dataset listing ----"
          ls -la MLProject/heart_preprocessed
          echo "---- csv files ----"
          find MLProject/heart_preprocessed -maxdepth 1 -type f -name "*.csv" | sort

      # 1) Retrain via MLflow Project (local env manager = no conda)
      - name: MLflow Project - Train (local env manager)
        run: |
          mlflow run MLProject -e main \
            --env-manager local \
            -P data_dir="${{ env.DATA_DIR }}" \
            -P experiment_name="${{ env.EXPERIMENT_NAME }}" \
            -P run_name="${{ env.RUN_NAME }}"

      # 2) Upload artifact mlruns
      - name: Upload MLflow runs (mlruns)
        uses: actions/upload-artifact@v4
        with:
          name: mlruns
          path: mlruns
          if-no-files-found: error

      # 3) Get latest run_id from experiment
      - name: Get latest run_id
        id: get_run
        run: |
          python - <<'PY'
          import os
          import mlflow
          from mlflow.tracking import MlflowClient

          tracking_uri = os.environ.get("MLFLOW_TRACKING_URI")
          if tracking_uri:
            mlflow.set_tracking_uri(tracking_uri)

          exp_name = os.environ["EXPERIMENT_NAME"]
          client = MlflowClient()

          exp = client.get_experiment_by_name(exp_name)
          if exp is None:
            raise SystemExit(f"Experiment '{exp_name}' not found.")

          runs = client.search_runs(
            experiment_ids=[exp.experiment_id],
            order_by=["attributes.start_time DESC"],
            max_results=1
          )
          if not runs:
            raise SystemExit("Tidak ada run ditemukan.")

          run_id = runs[0].info.run_id
          print("LATEST_RUN_ID:", run_id)

          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
            f.write(f"run_id={run_id}\n")
          PY

      # 4) Login DockerHub
      - name: Login DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      # 5) Build docker image from MLflow model
      # Jika artifact model kamu bukan "model", ganti /model jadi nama artifact yang benar.
      - name: Build Docker image (mlflow build-docker)
        run: |
          mlflow models build-docker \
            --model-uri "runs:/${{ steps.get_run.outputs.run_id }}/model" \
            --name "${{ secrets.DOCKERHUB_USERNAME }}/heart-ci:latest" \
            --env-manager local

      # 6) Push
      - name: Push Docker image
        run: |
          docker push "${{ secrets.DOCKERHUB_USERNAME }}/heart-ci:latest"
